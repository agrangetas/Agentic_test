# ğŸ§  Plan d'ImplÃ©mentation : Agent d'Investigation d'Entreprises


# Rappel Objectif
Construire un systÃ¨me agentique personnalisable, orchestrÃ© maison, capable de collecter, structurer et rÃ©sumer les donnÃ©es d'une entreprise (et de ses entreprises liÃ©es), avec stockage et mÃ©moire, en utilisant diffÃ©rents LLM et outils, dans un environnement DockerisÃ©.


## ğŸ¯ Objectif

Construire un **agent autonome** capable, Ã  partir du nom d'une entreprise, de :

* Identifier son site et informations de base
* Extraire et structurer ses activitÃ©s, liens capitalistiques, CA, actualitÃ©s
* Explorer rÃ©cursivement les entreprises liÃ©es
* Stocker les rÃ©sultats structurÃ©s dans une base de donnÃ©es PostgreSQL

## ğŸ—ï¸ Architecture Globale

```
[ EntrÃ©e utilisateur (nom entreprise) ]
              â”‚
              â–¼
     [ Orchestrateur Maison ]
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼         â–¼                     â–¼
[ Agent Normalization ] [ Agent Info ] [ Agent INPI ]
    â”‚                      â”‚             â”‚
    â–¼                      â–¼             â–¼
[ Agent Validation ] [ Agent News ] [ Agent Capital ]
    â”‚                      â”‚             â”‚
    â–¼                      â–¼             â–¼
[Tools & LLMs] â”€â”€â”€â”€â”€> [Tools & LLMs] <â”€â”€â”€ [Tools & LLMs]
    â”‚                      â”‚             â”‚
              â–¼
[ Graph de connaissance temporaire ]
              â”‚
              â–¼
[ RÃ©cursivitÃ© contrÃ´lÃ©e (entreprises liÃ©es) ]
              â”‚
              â–¼
[ Base PostgreSQL ]
```

## ğŸ§© Composants

### 1. Orchestrateur Maison

**RÃ´le :** orchestrer les agents, gÃ©rer la stratÃ©gie, contrÃ´ler la rÃ©cursivitÃ© et la profondeur, historiser les actions.

**Ã€ inclure :**

* File d'exÃ©cution des agents (ordonnancement avec dÃ©pendances)
* Arbre d'actions avec mÃ©moire locale temporaire
* Logique de choix du modÃ¨le (GPT-4 / Mistral / Claude) en fonction de la tÃ¢che
* Gestion de profondeur et cycles avec critÃ¨res d'arrÃªt intelligents
* Ã‰tat local de session (par entreprise) avec cache TTL
* Moteur de raisonnement (via prompts LLM ou rÃ¨gles)
* **SystÃ¨me de scoring de fiabilitÃ© des sources**
* **Gestion des conflits de donnÃ©es entre sources**
* **Fallback automatique en cas d'Ã©chec d'API**

**StratÃ©gie de dÃ©marrage :**
```
1. AgentNormalization (normalise le nom d'entrÃ©e)
2. AgentIdentification (trouve SIREN + URL)
3. ParallÃ¨le: [AgentWebData, AgentINPI, AgentNews]
4. AgentCapital (utilise donnÃ©es INPI)
5. AgentValidation (vÃ©rifie cohÃ©rence)
6. AgentRecursion (si pertinent)
7. AgentSynthese (gÃ©nÃ¨re rÃ©sumÃ© final)
```

### 2. Agents spÃ©cialisÃ©s

Chaque agent est un module avec :

* Objectif prÃ©cis
* ModÃ¨le LLM spÃ©cifique (ajustÃ© selon complexitÃ©)
* Outils associÃ©s
* MÃ©moire locale optionnelle
* InterprÃ©tation des rÃ©sultats et renvoi structurÃ©
* **SystÃ¨me de scoring de confiance des donnÃ©es**

**Agents principaux :**

* `AgentNormalization` â†’ **[NOUVEAU]** Normalise et dÃ©duplique les noms d'entreprises
* `AgentIdentification` â†’ Trouve SIREN/URL via matching + API externe
* `AgentWebData` â†’ Interroge PostgreSQL pour info extraite du site web
* `AgentINPI` â†’ RÃ©cupÃ¨re doc INPI, appelle outil de parsing
* `AgentCapitalLinks` â†’ Extrait capital/filiales depuis INPI structurÃ©
* `AgentNewsIntel` â†’ Analyse actualitÃ©s extraites, identifie Ã©vÃ©nements clÃ©s
* `AgentValidation` â†’ **[NOUVEAU]** VÃ©rifie cohÃ©rence des donnÃ©es entre sources
* `AgentRecursion` â†’ DÃ©tecte entitÃ©s liÃ©es et redÃ©marre avec critÃ¨res intelligents
* `AgentSynthese` â†’ GÃ©nÃ¨re rÃ©sumÃ© structurÃ© multi-format

**DÃ©tail des nouveaux agents :**

#### AgentNormalization
- **EntrÃ©e :** Nom d'entreprise brut (ex: "LVMH", "Louis Vuitton SA")
- **Sortie :** Nom normalisÃ© + variantes possibles + score de confiance
- **Outils :** `tool_normalize_name`, `tool_match_enterprise`, `tool_ner_extraction`

#### AgentValidation
- **EntrÃ©e :** DonnÃ©es collectÃ©es de multiple sources
- **Sortie :** DonnÃ©es validÃ©es + conflits identifiÃ©s + scores de fiabilitÃ©
- **Outils :** `tool_validate_consistency`, `tool_resolve_conflicts`

### 3. Outils

**RÃ´le :** ExÃ©cuter les actions concrÃ¨tes, renvoyer un format standard (type JSON).

**CaractÃ©ristiques :**

* Retourne donnÃ©es **factices mais formatÃ©es** pour tests
* Chaque outil = module Python indÃ©pendant, avec `run(input) â†’ output`
* **Gestion d'erreurs gracieuse avec fallbacks**
* **SystÃ¨me de cache intÃ©grÃ©**
* Peut Ãªtre mockÃ© ou branchÃ© sur une API rÃ©elle plus tard

**Outils existants amÃ©liorÃ©s :**

* `tool_identify_website(name)` â†’ avec fallback si Ã©chec
* `tool_fetch_site_data(url)` â†’ avec timeout et retry
* `tool_get_inpi_documents(name_or_siren)` â†’ avec cache
* `tool_parse_inpi_documents(documents)` â†’ avec validation
* `tool_extract_news(name_or_siren)` â†’ avec dÃ©duplication
* `tool_extract_links(structured_data)` â†’ avec scoring
* `tool_store_pg(data)` â†’ avec gestion de conflits

**Nouveaux outils :**

* `tool_normalize_name(raw_name)` â†’ Normalise un nom d'entreprise
* `tool_match_enterprise(name_variants)` â†’ Trouve SIREN/ID via matching flou
* `tool_ner_extraction(text)` â†’ Extrait entitÃ©s nommÃ©es (entreprises, personnes)
* `tool_validate_consistency(data_sources)` â†’ Valide cohÃ©rence entre sources
* `tool_resolve_conflicts(conflicting_data)` â†’ RÃ©sout conflits avec rÃ¨gles
* `tool_prioritize_entities(entities_list)` â†’ Priorise entitÃ©s pour rÃ©cursion
* `tool_generate_report(data, format)` â†’ GÃ©nÃ¨re rapport (JSON/HTML/PDF)

### 4. ModÃ¨les LLM (pluggables)

**StratÃ©gie amÃ©liorÃ©e :**

```yaml
defaults:
  provider: openai
  model: gpt-4o
  fallback_model: gpt-3.5-turbo

per_task:
  normalize_name:
    provider: openai
    model: gpt-3.5-turbo
  
  extract_site_info:
    provider: openai
    model: gpt-3.5-turbo

  parse_inpi_docs:
    provider: openai
    model: gpt-4-turbo
    fallback_model: gpt-4o

  ner_extraction:
    provider: openai
    model: gpt-4o

  validate_consistency:
    provider: openai
    model: gpt-4-turbo

  summarization:
    provider: openai
    model: gpt-4o

  conflict_resolution:
    provider: openai
    model: gpt-4-turbo

  reasoning:
    provider: openai
    model: gpt-4o

  link_analysis:
    provider: openai
    model: gpt-4-turbo
```

**Routing basÃ© sur :**

* TÃ¢che (analyse > extraction)
* Taille des donnÃ©es
* PrÃ©cision attendue
* **DisponibilitÃ© des modÃ¨les (fallback automatique)**

### 5. Graph de connaissance temporaire

**Structure :** Graph orientÃ© temporaire par session (en mÃ©moire ou Redis pour perfs).

**Contenu :**

* NÅ“uds : entitÃ©s (entreprise, personne, Ã©vÃ©nement) avec scores de confiance
* ArÃªtes : relations (filiale, partenaire, mentionnÃ©e dans, CA liÃ© Ã , etc.) avec poids
* AnnotÃ© par agent/source + timestamp
* **SystÃ¨me de versioning pour tracking des modifications**
* Peut Ãªtre exportÃ© en JSON-Graph, GraphQL ou visualisÃ© via D3.js

**Nouvelles fonctionnalitÃ©s :**
* DÃ©tection automatique de cycles
* Calcul de centralitÃ© pour identifier entitÃ©s clÃ©s
* Merge intelligent de nÅ“uds similaires

### 6. ContrÃ´le de rÃ©cursivitÃ© intelligente

**Objectif :** Ã©viter cycles et explosion combinatoire avec critÃ¨res intelligents

**CritÃ¨res d'arrÃªt prÃ©cis :**

```python
RECURSION_CRITERIA = {
    "max_depth": 3,
    "min_participation_percent": 10.0,  # % de participation minimum
    "min_ca_threshold": 1_000_000,      # CA minimum en euros
    "relevant_sectors": ["tech", "finance", "pharma"],  # Secteurs prioritaires
    "max_entities_per_level": 5,        # Max entitÃ©s par niveau
    "similarity_threshold": 0.8,        # Ã‰viter doublons
    "time_limit_minutes": 30            # Limite temps par session
}
```

**MÃ©canisme amÃ©liorÃ© :**

* Niveau de profondeur max configurable par session
* **Scoring de pertinence des entreprises liÃ©es** (CA, %, secteur)
* Cache mÃ©moire / DB pour Ã©viter de re-traiter
* **Priorisation intelligente** via `tool_prioritize_entities`
* **ArrÃªt anticipÃ©** si trop d'entitÃ©s dÃ©couvertes

### 7. SystÃ¨me de cache et mÃ©moire

**MÃ©moire des agents :**
* Contexte local par agent (session-based)
* MÃ©moire court terme (Redis avec TTL configurable)
* MÃ©moire long terme (PostgreSQL avec historique)

**Politique de cache :**
```python
CACHE_POLICY = {
    "enterprise_data": {"ttl": "7d", "invalidate_on": ["inpi_update"]},
    "news_data": {"ttl": "1d", "invalidate_on": ["time"]},
    "web_data": {"ttl": "3d", "invalidate_on": ["url_change"]},
    "inpi_data": {"ttl": "30d", "invalidate_on": ["manual_refresh"]}
}
```

---

## ğŸ—„ï¸ Base de DonnÃ©es PostgreSQL

**SchÃ©ma amÃ©liorÃ© :**

```sql
-- Table principale des entreprises
entreprises (
  id UUID PRIMARY KEY,
  nom TEXT NOT NULL,
  nom_normalise TEXT, -- Nouveau : nom normalisÃ©
  variantes_nom TEXT[], -- Nouveau : variantes du nom
  siren TEXT UNIQUE,
  url TEXT,
  date_creation DATE,
  secteur TEXT,
  ca_estime BIGINT, -- Nouveau : CA estimÃ©
  taille_entreprise TEXT, -- Nouveau : PME/ETI/GE
  resume TEXT,
  score_confiance FLOAT DEFAULT 0.5,
  date_maj TIMESTAMP DEFAULT NOW(),
  source_principale TEXT -- Nouveau : source principale des donnÃ©es
);

-- Nouveau : table des sources de donnÃ©es
sources_donnees (
  id UUID PRIMARY KEY,
  nom TEXT NOT NULL,
  type TEXT, -- inpi, web, news, api
  fiabilite_score FLOAT DEFAULT 0.5,
  derniere_maj TIMESTAMP DEFAULT NOW()
);

documents_inpi (
  id UUID PRIMARY KEY,
  entreprise_id UUID REFERENCES entreprises(id),
  type TEXT,
  contenu JSONB,
  date_maj TIMESTAMP DEFAULT NOW(),
  score_confiance FLOAT DEFAULT 0.8
);

liens_capitaux (
  id UUID PRIMARY KEY,
  entreprise_source UUID REFERENCES entreprises(id),
  entreprise_cible UUID REFERENCES entreprises(id),
  type_lien TEXT,
  pourcentage FLOAT,
  montant BIGINT, -- Nouveau : montant en euros
  date_lien DATE, -- Nouveau : date du lien
  source_id UUID REFERENCES sources_donnees(id),
  score_confiance FLOAT DEFAULT 0.5
);

actualites (
  id UUID PRIMARY KEY,
  entreprise_id UUID REFERENCES entreprises(id),
  date DATE,
  type TEXT,
  titre TEXT, -- Nouveau : titre de l'actualitÃ©
  resume TEXT,
  impact_estime TEXT, -- Nouveau : impact estimÃ© (positif/nÃ©gatif/neutre)
  source TEXT,
  url_source TEXT, -- Nouveau : URL de la source
  score_confiance FLOAT DEFAULT 0.3
);

-- Nouveau : table des conflits de donnÃ©es
conflits_donnees (
  id UUID PRIMARY KEY,
  entreprise_id UUID REFERENCES entreprises(id),
  champ_conflit TEXT,
  valeur_source1 TEXT,
  valeur_source2 TEXT,
  source1_id UUID REFERENCES sources_donnees(id),
  source2_id UUID REFERENCES sources_donnees(id),
  statut TEXT DEFAULT 'non_resolu', -- non_resolu, resolu, ignore
  resolution TEXT,
  date_detection TIMESTAMP DEFAULT NOW()
);

exploration_logs (
  id UUID PRIMARY KEY,
  session_id UUID, -- Nouveau : ID de session
  entreprise_id UUID REFERENCES entreprises(id),
  agent TEXT,
  input JSONB,
  output JSONB,
  duree_execution INTEGER, -- Nouveau : durÃ©e en secondes
  statut TEXT, -- Nouveau : success, error, timeout
  date_executed TIMESTAMP DEFAULT NOW()
);

-- Nouveau : table des sessions d'exploration
sessions_exploration (
  id UUID PRIMARY KEY,
  entreprise_initiale TEXT,
  parametres JSONB, -- CritÃ¨res de rÃ©cursivitÃ©, profondeur, etc.
  statut TEXT DEFAULT 'en_cours', -- en_cours, termine, erreur
  nb_entreprises_trouvees INTEGER DEFAULT 0,
  date_debut TIMESTAMP DEFAULT NOW(),
  date_fin TIMESTAMP,
  resume_final TEXT
);
```

---

## ğŸ§ª Tests et Debugging

### Mode "FAKE" amÃ©liorÃ©

* Chaque outil retourne des donnÃ©es simulÃ©es **avec variabilitÃ© rÃ©aliste**
* **Simulation de conflits de donnÃ©es** pour tester la validation
* **Simulation d'Ã©checs d'API** pour tester les fallbacks
* DonnÃ©es avec scores de confiance variables

### Mode "TRACE" amÃ©liorÃ©

* Activation d'une trace JSON de toutes les dÃ©cisions, outputs intermÃ©diaires
* **Dashboard web temps rÃ©el** pour visualiser l'exploration
* **MÃ©triques de performance** par agent et par outil
* **Export des conflits dÃ©tectÃ©s** pour analyse

### Mode "BENCHMARK"

* **Nouveau :** Comparaison de performance entre modÃ¨les LLM
* MÃ©triques de qualitÃ© des rÃ©sultats (prÃ©cision, rappel)
* Temps d'exÃ©cution par composant

---

## ğŸ”§ Stack technique recommandÃ©e

| Composant         | Techno                             |
| ----------------- | ---------------------------------- |
| Langage principal | Python 3.11                        |
| Framework agent   | Custom orchestrateur maison        |
| Stockage          | PostgreSQL 15+                     |
| MÃ©moire rapide    | Redis 7+ (pour cache et sessions)  |
| LLM access        | OpenAI, Anthropic, Mistral via API |
| Env. dev          | Cursor, Poetry, Pytest             |
| Graph             | NetworkX / Graphviz / D3.js        |
| Dashboard         | FastAPI + React (optionnel)        |
| Logging           | Loguru avec structured logging     |
| Monitoring        | Prometheus + Grafana (optionnel)   |
| Docker            | Docker compose                     |
| Queue             | Celery + Redis (pour async)        |

---

### Structure envisagÃ©e amÃ©liorÃ©e:
```
project-root/
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ models.yaml
â”‚   â”œâ”€â”€ recursion_criteria.yaml
â”‚   â””â”€â”€ cache_policy.yaml
â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ model_router.py
â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ conflict_resolver.py          # Nouveau
â”‚   â”œâ”€â”€ cache_manager.py              # Nouveau
â”‚   â””â”€â”€ agents/
â”‚       â”œâ”€â”€ agent_master.py
â”‚       â”œâ”€â”€ agent_normalization.py    # Nouveau
â”‚       â”œâ”€â”€ agent_identification.py
â”‚       â”œâ”€â”€ agent_webdata.py
â”‚       â”œâ”€â”€ agent_inpi.py
â”‚       â”œâ”€â”€ agent_capital.py
â”‚       â”œâ”€â”€ agent_news.py
â”‚       â”œâ”€â”€ agent_validation.py       # Nouveau
â”‚       â”œâ”€â”€ agent_recursion.py
â”‚       â””â”€â”€ agent_synthese.py  
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ tool_normalize_name.py        # Nouveau
â”‚   â”œâ”€â”€ tool_match_enterprise.py      # Nouveau
â”‚   â”œâ”€â”€ tool_ner_extraction.py        # Nouveau
â”‚   â”œâ”€â”€ tool_identify_website.py
â”‚   â”œâ”€â”€ tool_fetch_site_data.py
â”‚   â”œâ”€â”€ tool_get_inpi_documents.py
â”‚   â”œâ”€â”€ tool_parse_inpi_documents.py
â”‚   â”œâ”€â”€ tool_extract_news.py
â”‚   â”œâ”€â”€ tool_extract_links.py
â”‚   â”œâ”€â”€ tool_validate_consistency.py  # Nouveau
â”‚   â”œâ”€â”€ tool_resolve_conflicts.py     # Nouveau
â”‚   â”œâ”€â”€ tool_prioritize_entities.py   # Nouveau
â”‚   â”œâ”€â”€ tool_generate_report.py       # Nouveau
â”‚   â””â”€â”€ tool_store_pg.py
â”‚
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ memory_manager.py
â”‚   â”œâ”€â”€ cache_manager.py              # Nouveau
â”‚   â””â”€â”€ graph_temp.py
â”‚
â”œâ”€â”€ validation/                       # Nouveau dossier
â”‚   â”œâ”€â”€ data_validator.py
â”‚   â”œâ”€â”€ conflict_detector.py
â”‚   â””â”€â”€ scoring_engine.py
â”‚
â”œâ”€â”€ monitoring/                       # Nouveau dossier
â”‚   â”œâ”€â”€ metrics_collector.py
â”‚   â”œâ”€â”€ dashboard_api.py
â”‚   â””â”€â”€ performance_tracker.py
â”‚
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ init.sql
â”‚   â”œâ”€â”€ migrations/
â”‚   â””â”€â”€ seeds/                        # DonnÃ©es de test
â”‚
â”œâ”€â”€ frontend/                         # Nouveau (optionnel)
â”‚   â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ visualization/
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_fake_flows.py
    â”œâ”€â”€ test_conflict_resolution.py   # Nouveau
    â”œâ”€â”€ test_recursion_limits.py      # Nouveau
    â””â”€â”€ test_performance.py           # Nouveau
```

## ğŸ“Š MÃ©triques de SuccÃ¨s

**Quantitatives :**
- Temps moyen d'exploration : < 5 minutes pour profondeur 2
- Taux de succÃ¨s d'identification : > 95%
- PrÃ©cision des liens capitalistiques : > 90%
- Taux de conflits rÃ©solus automatiquement : > 80%

**Qualitatives :**
- RÃ©sumÃ©s cohÃ©rents et complets
- DÃ©tection proactive des incohÃ©rences
- Exploration intelligente sans explosion combinatoire
- Fallbacks gracieux en cas d'Ã©chec

---



## ğŸ”§ Exemple d'architecture Technique DÃ©taillÃ©e

### 1. Orchestrateur Custom - Design Patterns & Classes

#### Pattern Principal : **State Machine + Command Pattern**

```python
# orchestrator/core.py
from enum import Enum
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from abc import ABC, abstractmethod
import asyncio
from celery import Celery

class ExecutionState(Enum):
    PENDING = "pending"
    RUNNING = "running" 
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

class TaskPriority(Enum):
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class TaskContext:
    """Context partagÃ© entre tous les agents"""
    session_id: str
    enterprise_name: str
    current_depth: int
    max_depth: int
    collected_data: Dict[str, Any]
    graph: 'TemporaryGraph'
    cache: 'CacheManager'
    config: Dict[str, Any]
    errors: List[str]
    metrics: Dict[str, float]

class AgentTask(ABC):
    """Interface pour toutes les tÃ¢ches d'agents"""
    
    def __init__(self, task_id: str, priority: TaskPriority = TaskPriority.MEDIUM):
        self.task_id = task_id
        self.priority = priority
        self.state = ExecutionState.PENDING
        self.dependencies: List[str] = []
        self.result: Optional[Any] = None
        self.error: Optional[Exception] = None
        self.start_time: Optional[float] = None
        self.end_time: Optional[float] = None
    
    @abstractmethod
    async def execute(self, context: TaskContext) -> Any:
        """ExÃ©cute la tÃ¢che de maniÃ¨re asynchrone"""
        pass
    
    @abstractmethod
    def can_run(self, completed_tasks: List[str]) -> bool:
        """VÃ©rifie si la tÃ¢che peut Ãªtre exÃ©cutÃ©e"""
        pass
    
    def get_retry_count(self) -> int:
        return getattr(self, '_retry_count', 0)
    
    def increment_retry(self):
        self._retry_count = getattr(self, '_retry_count', 0) + 1

class OrchestrationEngine:
    """Moteur principal d'orchestration"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.celery_app = Celery('agent_orchestrator')
        self.task_queue = asyncio.PriorityQueue()
        self.running_tasks: Dict[str, asyncio.Task] = {}
        self.completed_tasks: List[str] = []
        self.failed_tasks: List[str] = []
        self.max_concurrent_tasks = config.get('max_concurrent_tasks', 5)
        self.retry_policy = config.get('retry_policy', {
            'max_retries': 3,
            'delay': 1.0,
            'backoff_factor': 2.0
        })
    
    async def execute_session(self, enterprise_name: str, session_config: Dict[str, Any]) -> 'SessionResult':
        """Point d'entrÃ©e principal pour une session d'exploration"""
        context = await self._create_context(enterprise_name, session_config)
        
        # CrÃ©ation du pipeline de tÃ¢ches
        tasks = await self._create_task_pipeline(context)
        
        # ExÃ©cution avec gestion des dÃ©pendances
        result = await self._execute_with_dependencies(tasks, context)
        
        return result
    
    async def _execute_with_dependencies(self, tasks: List[AgentTask], context: TaskContext) -> 'SessionResult':
        """ExÃ©cute les tÃ¢ches en respectant les dÃ©pendances"""
        pending_tasks = {task.task_id: task for task in tasks}
        
        while pending_tasks or self.running_tasks:
            # Trouve les tÃ¢ches prÃªtes Ã  Ãªtre exÃ©cutÃ©es
            ready_tasks = [
                task for task in pending_tasks.values()
                if task.can_run(self.completed_tasks) and len(self.running_tasks) < self.max_concurrent_tasks
            ]
            
            # Lance les tÃ¢ches prÃªtes
            for task in ready_tasks:
                await self._execute_task_async(task, context)
                del pending_tasks[task.task_id]
            
            # Attend qu'au moins une tÃ¢che se termine
            if self.running_tasks:
                done, pending = await asyncio.wait(
                    self.running_tasks.values(),
                    return_when=asyncio.FIRST_COMPLETED
                )
                
                for task in done:
                    task_id = self._get_task_id_from_task(task)
                    await self._handle_task_completion(task_id, task, context)
            
            await asyncio.sleep(0.1)  # Ã‰vite la busy loop
        
        return await self._build_session_result(context)
    
    async def _execute_task_async(self, agent_task: AgentTask, context: TaskContext):
        """ExÃ©cute une tÃ¢che de maniÃ¨re asynchrone avec retry"""
        
        async def task_wrapper():
            for attempt in range(self.retry_policy['max_retries'] + 1):
                try:
                    agent_task.state = ExecutionState.RUNNING
                    agent_task.start_time = time.time()
                    
                    result = await agent_task.execute(context)
                    
                    agent_task.result = result
                    agent_task.state = ExecutionState.COMPLETED
                    agent_task.end_time = time.time()
                    
                    return result
                
                except Exception as e:
                    agent_task.error = e
                    agent_task.increment_retry()
                    
                    if attempt < self.retry_policy['max_retries']:
                        delay = self.retry_policy['delay'] * (self.retry_policy['backoff_factor'] ** attempt)
                        await asyncio.sleep(delay)
                    else:
                        agent_task.state = ExecutionState.FAILED
                        agent_task.end_time = time.time()
                        raise
        
        task = asyncio.create_task(task_wrapper())
        self.running_tasks[agent_task.task_id] = task
        return task
```

#### Queue Management avec Celery

```python
# orchestrator/queue_manager.py
from celery import Celery
from kombu import Queue, Exchange
from typing import Dict, Any, Optional

class QueueManager:
    """Gestionnaire des queues Celery pour les tÃ¢ches lourdes"""
    
    def __init__(self, redis_url: str = "redis://localhost:6379/0"):
        self.celery_app = Celery('agent_tasks')
        self.celery_app.conf.update(
            broker_url=redis_url,
            result_backend=redis_url,
            task_serializer='json',
            accept_content=['json'],
            result_serializer='json',
            timezone='UTC',
            enable_utc=True,
            task_routes={
                'agent_tasks.heavy_processing': {'queue': 'heavy'},
                'agent_tasks.llm_calls': {'queue': 'llm'},
                'agent_tasks.web_scraping': {'queue': 'web'},
                'agent_tasks.data_processing': {'queue': 'data'}
            }
        )
        
        # DÃ©finition des queues avec prioritÃ©s
        self.celery_app.conf.task_queues = (
            Queue('heavy', Exchange('heavy'), routing_key='heavy',
                  queue_arguments={'x-max-priority': 10}),
            Queue('llm', Exchange('llm'), routing_key='llm',
                  queue_arguments={'x-max-priority': 8}),
            Queue('web', Exchange('web'), routing_key='web',
                  queue_arguments={'x-max-priority': 6}),
            Queue('data', Exchange('data'), routing_key='data',
                  queue_arguments={'x-max-priority': 4}),
        )
    
    @celery_app.task(bind=True, name='agent_tasks.llm_processing')
    def process_with_llm(self, agent_name: str, input_data: Dict[str, Any], model_config: Dict[str, Any]) -> Dict[str, Any]:
        """TÃ¢che Celery pour les appels LLM"""
        from agents.base import create_agent
        
        agent = create_agent(agent_name, model_config)
        result = agent.process_sync(input_data)
        
        return {
            'agent': agent_name,
            'result': result,
            'execution_time': time.time() - self.request.started,
            'model_used': model_config.get('model', 'unknown')
        }
    
    @celery_app.task(bind=True, name='agent_tasks.heavy_processing')
    def process_heavy_task(self, tool_name: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """TÃ¢che Celery pour les traitements lourds"""
        from tools.factory import create_tool
        
        tool = create_tool(tool_name)
        result = tool.run(input_data)
        
        return {
            'tool': tool_name,
            'result': result,
            'execution_time': time.time() - self.request.started
        }
```

### 2. Gestion Synchrone vs Asynchrone

#### StratÃ©gie Hybride

```python
# orchestrator/execution_strategy.py
import asyncio
from typing import List, Dict, Any, Union, Callable
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor

class ExecutionStrategy:
    """DÃ©termine la stratÃ©gie d'exÃ©cution optimale"""
    
    ASYNC_TASKS = {
        'web_scraping', 'api_calls', 'database_queries', 'file_io'
    }
    
    SYNC_HEAVY_TASKS = {
        'pdf_parsing', 'nlp_processing', 'image_processing'
    }
    
    PARALLEL_TASKS = {
        'data_validation', 'entity_extraction', 'conflict_resolution'
    }
    
    def __init__(self, max_workers: int = 4):
        self.thread_pool = ThreadPoolExecutor(max_workers=max_workers)
        self.process_pool = ProcessPoolExecutor(max_workers=max_workers)
    
    async def execute_optimal(self, task_type: str, func: Callable, *args, **kwargs) -> Any:
        """ExÃ©cute la fonction avec la stratÃ©gie optimale"""
        
        if task_type in self.ASYNC_TASKS:
            # ExÃ©cution asynchrone native
            return await func(*args, **kwargs)
            
        elif task_type in self.SYNC_HEAVY_TASKS:
            # ExÃ©cution dans un processus sÃ©parÃ©
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                self.process_pool, func, *args
            )
            
        elif task_type in self.PARALLEL_TASKS:
            # ExÃ©cution dans un thread sÃ©parÃ©
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                self.thread_pool, func, *args
            )
            
        else:
            # ExÃ©cution synchrone par dÃ©faut
            return func(*args, **kwargs)

# Exemple d'utilisation dans un agent
class AgentINPI(BaseAgent):
    
    async def execute(self, context: TaskContext) -> Dict[str, Any]:
        strategy = ExecutionStrategy()
        
        # RÃ©cupÃ©ration des documents (I/O intensif -> async)
        documents = await strategy.execute_optimal(
            'api_calls',
            self._fetch_inpi_documents,
            context.enterprise_name
        )
        
        # Parsing des PDFs (CPU intensif -> process)
        parsed_data = await strategy.execute_optimal(
            'pdf_parsing',
            self._parse_documents_heavy,
            documents
        )
        
        # Extraction d'entitÃ©s (parallÃ©lisable -> thread)
        entities = await strategy.execute_optimal(
            'entity_extraction',
            self._extract_entities,
            parsed_data
        )
        
        return {
            'documents': documents,
            'parsed_data': parsed_data,
            'entities': entities
        }
```

### 3. Classes et Interfaces DÃ©taillÃ©es

#### Base Classes pour Agents

```python
# agents/base.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import logging
from enum import Enum

class AgentState(Enum):
    IDLE = "idle"
    PROCESSING = "processing"
    COMPLETED = "completed"
    ERROR = "error"

@dataclass
class AgentResult:
    """RÃ©sultat standardisÃ© d'un agent"""
    agent_name: str
    success: bool
    data: Dict[str, Any]
    confidence_score: float
    execution_time: float
    errors: List[str]
    warnings: List[str]
    metadata: Dict[str, Any]

class BaseAgent(ABC):
    """Classe de base pour tous les agents"""
    
    def __init__(self, name: str, config: Dict[str, Any]):
        self.name = name
        self.config = config
        self.state = AgentState.IDLE
        self.logger = logging.getLogger(f"agent.{name}")
        self.memory = {}
        self.tools = []
        self.llm_client = None
        
    @abstractmethod
    async def execute(self, context: TaskContext) -> AgentResult:
        """MÃ©thode principale d'exÃ©cution"""
        pass
    
    @abstractmethod
    def validate_input(self, context: TaskContext) -> bool:
        """Valide les donnÃ©es d'entrÃ©e"""
        pass
    
    async def pre_execute(self, context: TaskContext):
        """PrÃ©paration avant exÃ©cution"""
        self.state = AgentState.PROCESSING
        self.logger.info(f"Starting execution for {context.enterprise_name}")
    
    async def post_execute(self, result: AgentResult, context: TaskContext):
        """Nettoyage aprÃ¨s exÃ©cution"""
        self.state = AgentState.COMPLETED if result.success else AgentState.ERROR
        
        # Mise Ã  jour du contexte
        context.collected_data[self.name] = result.data
        context.metrics[f"{self.name}_confidence"] = result.confidence_score
        context.metrics[f"{self.name}_execution_time"] = result.execution_time
        
        # Logging
        self.logger.info(f"Completed execution: success={result.success}, confidence={result.confidence_score}")

class DataValidationMixin:
    """Mixin pour validation des donnÃ©es"""
    
    def validate_data_consistency(self, data: Dict[str, Any]) -> List[str]:
        """Valide la cohÃ©rence des donnÃ©es"""
        errors = []
        
        # Validation des champs obligatoires
        required_fields = getattr(self, 'REQUIRED_FIELDS', [])
        for field in required_fields:
            if field not in data or not data[field]:
                errors.append(f"Missing required field: {field}")
        
        # Validation des types
        field_types = getattr(self, 'FIELD_TYPES', {})
        for field, expected_type in field_types.items():
            if field in data and not isinstance(data[field], expected_type):
                errors.append(f"Invalid type for {field}: expected {expected_type}, got {type(data[field])}")
        
        return errors

class CacheableMixin:
    """Mixin pour gestion du cache"""
    
    def get_cache_key(self, context: TaskContext) -> str:
        """GÃ©nÃ¨re une clÃ© de cache"""
        return f"{self.name}:{context.enterprise_name}:{hash(str(context.config))}"
    
    async def get_cached_result(self, context: TaskContext) -> Optional[AgentResult]:
        """RÃ©cupÃ¨re un rÃ©sultat depuis le cache"""
        cache_key = self.get_cache_key(context)
        return await context.cache.get(cache_key)
    
    async def cache_result(self, result: AgentResult, context: TaskContext):
        """Met en cache un rÃ©sultat"""
        cache_key = self.get_cache_key(context)
        ttl = self.config.get('cache_ttl', 3600)
        await context.cache.set(cache_key, result, ttl)
```

#### ImplÃ©mentation ConcrÃ¨te d'Agents

```python
# agents/agent_normalization.py
from typing import Dict, Any, List
from .base import BaseAgent, AgentResult, DataValidationMixin
from tools.factory import create_tool

class AgentNormalization(BaseAgent, DataValidationMixin):
    """Agent de normalisation des noms d'entreprises"""
    
    REQUIRED_FIELDS = ['enterprise_name']
    FIELD_TYPES = {'enterprise_name': str}
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__('normalization', config)
        self.normalize_tool = create_tool('normalize_name')
        self.match_tool = create_tool('match_enterprise')
        self.ner_tool = create_tool('ner_extraction')
    
    async def execute(self, context: TaskContext) -> AgentResult:
        start_time = time.time()
        errors = []
        warnings = []
        
        try:
            await self.pre_execute(context)
            
            # Validation des entrÃ©es
            if not self.validate_input(context):
                raise ValueError("Invalid input data")
            
            # Normalisation du nom
            normalized_result = await self.normalize_tool.run_async({
                'raw_name': context.enterprise_name
            })
            
            # Matching avec base de donnÃ©es
            match_result = await self.match_tool.run_async({
                'name_variants': normalized_result['variants']
            })
            
            # Extraction d'entitÃ©s nommÃ©es
            ner_result = await self.ner_tool.run_async({
                'text': context.enterprise_name
            })
            
            # Consolidation des rÃ©sultats
            consolidated_data = {
                'original_name': context.enterprise_name,
                'normalized_name': normalized_result['normalized'],
                'variants': normalized_result['variants'],
                'matched_entities': match_result['matches'],
                'siren': match_result.get('best_match', {}).get('siren'),
                'confidence_score': match_result.get('confidence', 0.0),
                'named_entities': ner_result['entities']
            }
            
            # Validation des donnÃ©es
            validation_errors = self.validate_data_consistency(consolidated_data)
            if validation_errors:
                errors.extend(validation_errors)
            
            execution_time = time.time() - start_time
            
            result = AgentResult(
                agent_name=self.name,
                success=len(errors) == 0,
                data=consolidated_data,
                confidence_score=consolidated_data['confidence_score'],
                execution_time=execution_time,
                errors=errors,
                warnings=warnings,
                metadata={
                    'variants_found': len(normalized_result['variants']),
                    'matches_found': len(match_result['matches']),
                    'entities_extracted': len(ner_result['entities'])
                }
            )
            
            await self.post_execute(result, context)
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            errors.append(str(e))
            
            return AgentResult(
                agent_name=self.name,
                success=False,
                data={},
                confidence_score=0.0,
                execution_time=execution_time,
                errors=errors,
                warnings=warnings,
                metadata={}
            )
    
    def validate_input(self, context: TaskContext) -> bool:
        if not context.enterprise_name or not context.enterprise_name.strip():
            return False
        return True
```

### 4. Gestion des Ã‰tats et Transitions

```python
# orchestrator/state_manager.py
from enum import Enum
from typing import Dict, Any, List, Optional, Callable
from dataclasses import dataclass
import asyncio

class SessionState(Enum):
    INITIALIZING = "initializing"
    NORMALIZING = "normalizing"
    IDENTIFYING = "identifying"
    COLLECTING = "collecting"
    VALIDATING = "validating"
    RECURSING = "recursing"
    SYNTHESIZING = "synthesizing"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class StateTransition:
    from_state: SessionState
    to_state: SessionState
    condition: Callable[[TaskContext], bool]
    action: Optional[Callable[[TaskContext], Any]] = None

class StateManager:
    """Gestionnaire d'Ã©tats pour les sessions d'exploration"""
    
    def __init__(self):
        self.transitions: List[StateTransition] = []
        self._setup_transitions()
    
    def _setup_transitions(self):
        """DÃ©finit les transitions d'Ã©tats autorisÃ©es"""
        self.transitions = [
            StateTransition(
                SessionState.INITIALIZING,
                SessionState.NORMALIZING,
                lambda ctx: ctx.enterprise_name is not None
            ),
            StateTransition(
                SessionState.NORMALIZING,
                SessionState.IDENTIFYING,
                lambda ctx: 'normalization' in ctx.collected_data and ctx.collected_data['normalization'].get('normalized_name')
            ),
            StateTransition(
                SessionState.IDENTIFYING,
                SessionState.COLLECTING,
                lambda ctx: 'identification' in ctx.collected_data and ctx.collected_data['identification'].get('siren')
            ),
            StateTransition(
                SessionState.COLLECTING,
                SessionState.VALIDATING,
                lambda ctx: len(ctx.collected_data) >= 3  # Au moins 3 agents ont collectÃ© des donnÃ©es
            ),
            StateTransition(
                SessionState.VALIDATING,
                SessionState.RECURSING,
                lambda ctx: (
                    'validation' in ctx.collected_data and
                    ctx.current_depth < ctx.max_depth and
                    len(ctx.collected_data.get('validation', {}).get('linked_entities', [])) > 0
                )
            ),
            StateTransition(
                SessionState.VALIDATING,
                SessionState.SYNTHESIZING,
                lambda ctx: (
                    ctx.current_depth >= ctx.max_depth or
                    len(ctx.collected_data.get('validation', {}).get('linked_entities', [])) == 0
                )
            ),
            StateTransition(
                SessionState.RECURSING,
                SessionState.COLLECTING,
                lambda ctx: True  # Retour Ã  la collecte pour les entitÃ©s liÃ©es
            ),
            StateTransition(
                SessionState.SYNTHESIZING,
                SessionState.COMPLETED,
                lambda ctx: 'synthesis' in ctx.collected_data
            )
        ]
    
    def get_next_state(self, current_state: SessionState, context: TaskContext) -> Optional[SessionState]:
        """DÃ©termine l'Ã©tat suivant basÃ© sur les conditions"""
        for transition in self.transitions:
            if transition.from_state == current_state and transition.condition(context):
                if transition.action:
                    transition.action(context)
                return transition.to_state
        return None
    
    def can_transition(self, from_state: SessionState, to_state: SessionState, context: TaskContext) -> bool:
        """VÃ©rifie si une transition est autorisÃ©e"""
        for transition in self.transitions:
            if transition.from_state == from_state and transition.to_state == to_state:
                return transition.condition(context)
        return False
```

### 5. Monitoring et MÃ©triques

```python
# monitoring/metrics_collector.py
from typing import Dict, Any, List
from dataclasses import dataclass, field
import time
import psutil
import asyncio
from prometheus_client import Counter, Histogram, Gauge

@dataclass
class SystemMetrics:
    cpu_usage: float
    memory_usage: float
    disk_usage: float
    network_io: Dict[str, float]
    timestamp: float = field(default_factory=time.time)

@dataclass
class AgentMetrics:
    agent_name: str
    execution_count: int
    success_rate: float
    avg_execution_time: float
    confidence_scores: List[float]
    error_count: int
    cache_hit_rate: float

class MetricsCollector:
    """Collecteur de mÃ©triques pour monitoring"""
    
    def __init__(self):
        # MÃ©triques Prometheus
        self.agent_executions = Counter('agent_executions_total', 'Total agent executions', ['agent_name', 'status'])
        self.execution_duration = Histogram('agent_execution_duration_seconds', 'Agent execution duration', ['agent_name'])
        self.confidence_scores = Histogram('agent_confidence_scores', 'Agent confidence scores', ['agent_name'])
        self.system_resources = Gauge('system_resources', 'System resource usage', ['resource_type'])
        
        self.agent_metrics: Dict[str, AgentMetrics] = {}
        self.system_metrics: List[SystemMetrics] = []
        
    async def collect_agent_metrics(self, agent_name: str, result: AgentResult):
        """Collecte les mÃ©triques d'un agent"""
        # Prometheus metrics
        status = 'success' if result.success else 'error'
        self.agent_executions.labels(agent_name=agent_name, status=status).inc()
        self.execution_duration.labels(agent_name=agent_name).observe(result.execution_time)
        self.confidence_scores.labels(agent_name=agent_name).observe(result.confidence_score)
        
        # MÃ©triques internes
        if agent_name not in self.agent_metrics:
            self.agent_metrics[agent_name] = AgentMetrics(
                agent_name=agent_name,
                execution_count=0,
                success_rate=0.0,
                avg_execution_time=0.0,
                confidence_scores=[],
                error_count=0,
                cache_hit_rate=0.0
            )
        
        metrics = self.agent_metrics[agent_name]
        metrics.execution_count += 1
        metrics.confidence_scores.append(result.confidence_score)
        
        if not result.success:
            metrics.error_count += 1
        
        # Recalculer les moyennes
        metrics.success_rate = (metrics.execution_count - metrics.error_count) / metrics.execution_count
        metrics.avg_execution_time = (
            (metrics.avg_execution_time * (metrics.execution_count - 1) + result.execution_time) / 
            metrics.execution_count
        )
    
    async def collect_system_metrics(self):
        """Collecte les mÃ©triques systÃ¨me"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        network = psutil.net_io_counters()
        
        system_metrics = SystemMetrics(
            cpu_usage=cpu_percent,
            memory_usage=memory.percent,
            disk_usage=disk.percent,
            network_io={
                'bytes_sent': network.bytes_sent,
                'bytes_recv': network.bytes_recv
            }
        )
        
        self.system_metrics.append(system_metrics)
        
        # Prometheus metrics
        self.system_resources.labels(resource_type='cpu').set(cpu_percent)
        self.system_resources.labels(resource_type='memory').set(memory.percent)
        self.system_resources.labels(resource_type='disk').set(disk.percent)
        
        # Garder seulement les 1000 derniÃ¨res mesures
        if len(self.system_metrics) > 1000:
            self.system_metrics = self.system_metrics[-1000:]
    
    def get_summary_report(self) -> Dict[str, Any]:
        """GÃ©nÃ¨re un rapport de synthÃ¨se"""
        return {
            'agents': {
                name: {
                    'execution_count': metrics.execution_count,
                    'success_rate': metrics.success_rate,
                    'avg_execution_time': metrics.avg_execution_time,
                    'avg_confidence': sum(metrics.confidence_scores) / len(metrics.confidence_scores) if metrics.confidence_scores else 0.0,
                    'error_count': metrics.error_count
                }
                for name, metrics in self.agent_metrics.items()
            },
            'system': {
                'current_cpu': self.system_metrics[-1].cpu_usage if self.system_metrics else 0.0,
                'current_memory': self.system_metrics[-1].memory_usage if self.system_metrics else 0.0,
                'current_disk': self.system_metrics[-1].disk_usage if self.system_metrics else 0.0
            },
            'timestamp': time.time()
        }
```




## ğŸªœ Ã‰tapes de dÃ©veloppement

### Phase 1 â€“ Base agent + outils fake + validation

* [ ] ImplÃ©mentation de l'orchestrateur avec gestion d'erreurs
* [ ] **AgentNormalization avec outils de matching**
* [ ] ImplÃ©mentation des agents avec modules d'outils factices
* [ ] **SystÃ¨me de validation et rÃ©solution de conflits**
* [ ] Structure du graph mÃ©moire local avec scoring
* [ ] Connecteurs PostgreSQL avec nouveau schÃ©ma
* [ ] **SystÃ¨me de cache Redis**

### Phase 2 â€“ MÃ©moire, rÃ©cursivitÃ© intelligente, profondeur

* [ ] Ajout mÃ©moire locale/long terme par agent
* [ ] **CritÃ¨res d'arrÃªt intelligents avec scoring de pertinence**
* [ ] Limiteur de profondeur + prÃ©vention des doublons
* [ ] **Priorisation automatique des entitÃ©s**
* [ ] Ajout d'un cache LRU avec TTL configurable

### Phase 3 â€“ InteropÃ©rabilitÃ© LLM et monitoring

* [ ] Module `model_router.py` avec fallbacks
* [ ] **Dashboard de monitoring en temps rÃ©el**
* [ ] Bench simple entre 3 modÃ¨les sur 5 tÃ¢ches
* [ ] **MÃ©triques de qualitÃ© et performance**
* [ ] Tests de raisonnement + logs de dÃ©cision

### Phase 4 â€“ Tests bout en bout et optimisation

* [ ] Tests sur cas d'entreprises fictives avec conflits
* [ ] **Tests de charge et limites de rÃ©cursivitÃ©**
* [ ] Exports JSON / visualisation Graph avancÃ©e
* [ ] **Optimisation des performances**
* [ ] DÃ©finition API REST (si besoin plus tard)

### Phase 5 â€“ Production ready (optionnel)

* [ ] Interface web pour configuration
* [ ] SystÃ¨me d'alertes et notifications
* [ ] Backup automatique et restauration
* [ ] Documentation utilisateur complÃ¨te

---