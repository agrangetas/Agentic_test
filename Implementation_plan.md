# üß† Plan d'Impl√©mentation : Agent d'Investigation d'Entreprises


# Rappel Objectif
Construire un syst√®me agentique personnalisable, orchestr√© maison, capable de collecter, structurer et r√©sumer les donn√©es d'une entreprise (et de ses entreprises li√©es), avec stockage et m√©moire, en utilisant diff√©rents LLM et outils, dans un environnement Dockeris√©.


## üéØ Objectif

Construire un **agent autonome** capable, √† partir du nom d'une entreprise, de :

* Identifier son site et informations de base
* Extraire et structurer ses activit√©s, liens capitalistiques, CA, actualit√©s
* Explorer r√©cursivement les entreprises li√©es
* Stocker les r√©sultats structur√©s dans une base de donn√©es PostgreSQL

## üèóÔ∏è Architecture Globale

```
[ Entr√©e utilisateur (nom entreprise) ]
              ‚îÇ
              ‚ñº
     [ Orchestrateur Maison ]
              ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº         ‚ñº                     ‚ñº
[ Agent Normalization ] [ Agent Info ] [ Agent INPI ]
    ‚îÇ                      ‚îÇ             ‚îÇ
    ‚ñº                      ‚ñº             ‚ñº
[ Agent Validation ] [ Agent News ] [ Agent Capital ]
    ‚îÇ                      ‚îÇ             ‚îÇ
    ‚ñº                      ‚ñº             ‚ñº
[Tools & LLMs] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> [Tools & LLMs] <‚îÄ‚îÄ‚îÄ [Tools & LLMs]
    ‚îÇ                      ‚îÇ             ‚îÇ
              ‚ñº
[ Graph de connaissance temporaire ]
              ‚îÇ
              ‚ñº
[ R√©cursivit√© contr√¥l√©e (entreprises li√©es) ]
              ‚îÇ
              ‚ñº
[ Base PostgreSQL ]
```

## üß© Composants

### 1. Orchestrateur Maison

**R√¥le :** orchestrer les agents, g√©rer la strat√©gie, contr√¥ler la r√©cursivit√© et la profondeur, historiser les actions.

**√Ä inclure :**

* File d'ex√©cution des agents (ordonnancement avec d√©pendances)
* Arbre d'actions avec m√©moire locale temporaire
* Logique de choix du mod√®le (GPT-4 / Mistral / Claude) en fonction de la t√¢che
* Gestion de profondeur et cycles avec crit√®res d'arr√™t intelligents
* √âtat local de session (par entreprise) avec cache TTL
* Moteur de raisonnement (via prompts LLM ou r√®gles)
* **Syst√®me de scoring de fiabilit√© des sources**
* **Gestion des conflits de donn√©es entre sources**
* **Fallback automatique en cas d'√©chec d'API**

**Strat√©gie de d√©marrage :**
```
1. AgentNormalization (normalise le nom d'entr√©e)
2. AgentIdentification (trouve SIREN + URL)
3. Parall√®le: [AgentWebData, AgentINPI, AgentNews]
4. AgentCapital (utilise donn√©es INPI)
5. AgentValidation (v√©rifie coh√©rence)
6. AgentRecursion (si pertinent)
7. AgentSynthese (g√©n√®re r√©sum√© final)
```

### 2. Agents sp√©cialis√©s

Chaque agent est un module avec :

* Objectif pr√©cis
* Mod√®le LLM sp√©cifique (ajust√© selon complexit√©)
* Outils associ√©s
* M√©moire locale optionnelle
* Interpr√©tation des r√©sultats et renvoi structur√©
* **Syst√®me de scoring de confiance des donn√©es**

**Agents principaux :**

* `AgentNormalization` ‚Üí **[NOUVEAU]** Normalise et d√©duplique les noms d'entreprises
* `AgentIdentification` ‚Üí Trouve SIREN/URL via matching + API externe
* `AgentWebData` ‚Üí Interroge PostgreSQL pour info extraite du site web
* `AgentINPI` ‚Üí R√©cup√®re doc INPI, appelle outil de parsing
* `AgentCapitalLinks` ‚Üí Extrait capital/filiales depuis INPI structur√©
* `AgentNewsIntel` ‚Üí Analyse actualit√©s extraites, identifie √©v√©nements cl√©s
* `AgentValidation` ‚Üí **[NOUVEAU]** V√©rifie coh√©rence des donn√©es entre sources
* `AgentRecursion` ‚Üí D√©tecte entit√©s li√©es et red√©marre avec crit√®res intelligents
* `AgentSynthese` ‚Üí G√©n√®re r√©sum√© structur√© multi-format

**D√©tail des nouveaux agents :**

#### AgentNormalization
- **Entr√©e :** Nom d'entreprise brut (ex: "LVMH", "Louis Vuitton SA")
- **Sortie :** Nom normalis√© + variantes possibles + score de confiance
- **Outils :** `tool_normalize_name`, `tool_match_enterprise`, `tool_ner_extraction`

#### AgentValidation
- **Entr√©e :** Donn√©es collect√©es de multiple sources
- **Sortie :** Donn√©es valid√©es + conflits identifi√©s + scores de fiabilit√©
- **Outils :** `tool_validate_consistency`, `tool_resolve_conflicts`

### 3. Outils

**R√¥le :** Ex√©cuter les actions concr√®tes, renvoyer un format standard (type JSON).

**Caract√©ristiques :**

* Retourne donn√©es **factices mais format√©es** pour tests
* Chaque outil = module Python ind√©pendant, avec `run(input) ‚Üí output`
* **Gestion d'erreurs gracieuse avec fallbacks**
* **Syst√®me de cache int√©gr√©**
* Peut √™tre mock√© ou branch√© sur une API r√©elle plus tard

**Outils existants am√©lior√©s :**

* `tool_identify_website(name)` ‚Üí avec fallback si √©chec
* `tool_fetch_site_data(url)` ‚Üí avec timeout et retry
* `tool_get_inpi_documents(name_or_siren)` ‚Üí avec cache
* `tool_parse_inpi_documents(documents)` ‚Üí avec validation
* `tool_extract_news(name_or_siren)` ‚Üí avec d√©duplication
* `tool_extract_links(structured_data)` ‚Üí avec scoring
* `tool_store_pg(data)` ‚Üí avec gestion de conflits

**Nouveaux outils :**

* `tool_normalize_name(raw_name)` ‚Üí Normalise un nom d'entreprise
* `tool_match_enterprise(name_variants)` ‚Üí Trouve SIREN/ID via matching flou
* `tool_ner_extraction(text)` ‚Üí Extrait entit√©s nomm√©es (entreprises, personnes)
* `tool_validate_consistency(data_sources)` ‚Üí Valide coh√©rence entre sources
* `tool_resolve_conflicts(conflicting_data)` ‚Üí R√©sout conflits avec r√®gles
* `tool_prioritize_entities(entities_list)` ‚Üí Priorise entit√©s pour r√©cursion
* `tool_generate_report(data, format)` ‚Üí G√©n√®re rapport (JSON/HTML/PDF)

### 4. Mod√®les LLM (pluggables)

**Strat√©gie am√©lior√©e :**

```yaml
defaults:
  provider: openai
  model: gpt-4o
  fallback_model: gpt-3.5-turbo

per_task:
  normalize_name:
    provider: openai
    model: gpt-3.5-turbo
  
  extract_site_info:
    provider: openai
    model: gpt-3.5-turbo

  parse_inpi_docs:
    provider: openai
    model: gpt-4-turbo
    fallback_model: gpt-4o

  ner_extraction:
    provider: openai
    model: gpt-4o

  validate_consistency:
    provider: openai
    model: gpt-4-turbo

  summarization:
    provider: openai
    model: gpt-4o

  conflict_resolution:
    provider: openai
    model: gpt-4-turbo

  reasoning:
    provider: openai
    model: gpt-4o

  link_analysis:
    provider: openai
    model: gpt-4-turbo
```

**Routing bas√© sur :**

* T√¢che (analyse > extraction)
* Taille des donn√©es
* Pr√©cision attendue
* **Disponibilit√© des mod√®les (fallback automatique)**

### 5. Graph de connaissance temporaire

**Structure :** Graph orient√© temporaire par session (en m√©moire ou Redis pour perfs).

**Contenu :**

* N≈ìuds : entit√©s (entreprise, personne, √©v√©nement) avec scores de confiance
* Ar√™tes : relations (filiale, partenaire, mentionn√©e dans, CA li√© √†, etc.) avec poids
* Annot√© par agent/source + timestamp
* **Syst√®me de versioning pour tracking des modifications**
* Peut √™tre export√© en JSON-Graph, GraphQL ou visualis√© via D3.js

**Nouvelles fonctionnalit√©s :**
* D√©tection automatique de cycles
* Calcul de centralit√© pour identifier entit√©s cl√©s
* Merge intelligent de n≈ìuds similaires

### 6. Contr√¥le de r√©cursivit√© intelligente

**Objectif :** √©viter cycles et explosion combinatoire avec crit√®res intelligents

**Crit√®res d'arr√™t pr√©cis :**

```python
RECURSION_CRITERIA = {
    "max_depth": 3,
    "min_participation_percent": 10.0,  # % de participation minimum
    "min_ca_threshold": 1_000_000,      # CA minimum en euros
    "relevant_sectors": ["tech", "finance", "pharma"],  # Secteurs prioritaires
    "max_entities_per_level": 5,        # Max entit√©s par niveau
    "similarity_threshold": 0.8,        # √âviter doublons
    "time_limit_minutes": 30            # Limite temps par session
}
```

**M√©canisme am√©lior√© :**

* Niveau de profondeur max configurable par session
* **Scoring de pertinence des entreprises li√©es** (CA, %, secteur)
* Cache m√©moire / DB pour √©viter de re-traiter
* **Priorisation intelligente** via `tool_prioritize_entities`
* **Arr√™t anticip√©** si trop d'entit√©s d√©couvertes

### 7. Syst√®me de cache et m√©moire

**M√©moire des agents :**
* Contexte local par agent (session-based)
* M√©moire court terme (Redis avec TTL configurable)
* M√©moire long terme (PostgreSQL avec historique)

**Politique de cache :**
```python
CACHE_POLICY = {
    "enterprise_data": {"ttl": "7d", "invalidate_on": ["inpi_update"]},
    "news_data": {"ttl": "1d", "invalidate_on": ["time"]},
    "web_data": {"ttl": "3d", "invalidate_on": ["url_change"]},
    "inpi_data": {"ttl": "30d", "invalidate_on": ["manual_refresh"]}
}
```

---

## üóÑÔ∏è Base de Donn√©es PostgreSQL

**Sch√©ma am√©lior√© :**

```sql
-- Table principale des entreprises
entreprises (
  id UUID PRIMARY KEY,
  nom TEXT NOT NULL,
  nom_normalise TEXT, -- Nouveau : nom normalis√©
  variantes_nom TEXT[], -- Nouveau : variantes du nom
  siren TEXT UNIQUE,
  url TEXT,
  date_creation DATE,
  secteur TEXT,
  ca_estime BIGINT, -- Nouveau : CA estim√©
  taille_entreprise TEXT, -- Nouveau : PME/ETI/GE
  resume TEXT,
  score_confiance FLOAT DEFAULT 0.5,
  date_maj TIMESTAMP DEFAULT NOW(),
  source_principale TEXT -- Nouveau : source principale des donn√©es
);

-- Nouveau : table des sources de donn√©es
sources_donnees (
  id UUID PRIMARY KEY,
  nom TEXT NOT NULL,
  type TEXT, -- inpi, web, news, api
  fiabilite_score FLOAT DEFAULT 0.5,
  derniere_maj TIMESTAMP DEFAULT NOW()
);

documents_inpi (
  id UUID PRIMARY KEY,
  entreprise_id UUID REFERENCES entreprises(id),
  type TEXT,
  contenu JSONB,
  date_maj TIMESTAMP DEFAULT NOW(),
  score_confiance FLOAT DEFAULT 0.8
);

liens_capitaux (
  id UUID PRIMARY KEY,
  entreprise_source UUID REFERENCES entreprises(id),
  entreprise_cible UUID REFERENCES entreprises(id),
  type_lien TEXT,
  pourcentage FLOAT,
  montant BIGINT, -- Nouveau : montant en euros
  date_lien DATE, -- Nouveau : date du lien
  source_id UUID REFERENCES sources_donnees(id),
  score_confiance FLOAT DEFAULT 0.5
);

actualites (
  id UUID PRIMARY KEY,
  entreprise_id UUID REFERENCES entreprises(id),
  date DATE,
  type TEXT,
  titre TEXT, -- Nouveau : titre de l'actualit√©
  resume TEXT,
  impact_estime TEXT, -- Nouveau : impact estim√© (positif/n√©gatif/neutre)
  source TEXT,
  url_source TEXT, -- Nouveau : URL de la source
  score_confiance FLOAT DEFAULT 0.3
);

-- Nouveau : table des conflits de donn√©es
conflits_donnees (
  id UUID PRIMARY KEY,
  entreprise_id UUID REFERENCES entreprises(id),
  champ_conflit TEXT,
  valeur_source1 TEXT,
  valeur_source2 TEXT,
  source1_id UUID REFERENCES sources_donnees(id),
  source2_id UUID REFERENCES sources_donnees(id),
  statut TEXT DEFAULT 'non_resolu', -- non_resolu, resolu, ignore
  resolution TEXT,
  date_detection TIMESTAMP DEFAULT NOW()
);

exploration_logs (
  id UUID PRIMARY KEY,
  session_id UUID, -- Nouveau : ID de session
  entreprise_id UUID REFERENCES entreprises(id),
  agent TEXT,
  input JSONB,
  output JSONB,
  duree_execution INTEGER, -- Nouveau : dur√©e en secondes
  statut TEXT, -- Nouveau : success, error, timeout
  date_executed TIMESTAMP DEFAULT NOW()
);

-- Nouveau : table des sessions d'exploration
sessions_exploration (
  id UUID PRIMARY KEY,
  entreprise_initiale TEXT,
  parametres JSONB, -- Crit√®res de r√©cursivit√©, profondeur, etc.
  statut TEXT DEFAULT 'en_cours', -- en_cours, termine, erreur
  nb_entreprises_trouvees INTEGER DEFAULT 0,
  date_debut TIMESTAMP DEFAULT NOW(),
  date_fin TIMESTAMP,
  resume_final TEXT
);
```

---

## üß™ Tests et Debugging

### Mode "FAKE" am√©lior√©

* Chaque outil retourne des donn√©es simul√©es **avec variabilit√© r√©aliste**
* **Simulation de conflits de donn√©es** pour tester la validation
* **Simulation d'√©checs d'API** pour tester les fallbacks
* Donn√©es avec scores de confiance variables

### Mode "TRACE" am√©lior√©

* Activation d'une trace JSON de toutes les d√©cisions, outputs interm√©diaires
* **Dashboard web temps r√©el** pour visualiser l'exploration
* **M√©triques de performance** par agent et par outil
* **Export des conflits d√©tect√©s** pour analyse

### Mode "BENCHMARK"

* **Nouveau :** Comparaison de performance entre mod√®les LLM
* M√©triques de qualit√© des r√©sultats (pr√©cision, rappel)
* Temps d'ex√©cution par composant

---

## üîß Stack technique recommand√©e

| Composant         | Techno                             |
| ----------------- | ---------------------------------- |
| Langage principal | Python 3.11                        |
| Framework agent   | Custom orchestrateur maison        |
| Stockage          | PostgreSQL 15+                     |
| M√©moire rapide    | Redis 7+ (pour cache et sessions)  |
| LLM access        | OpenAI, Anthropic, Mistral via API |
| Env. dev          | Cursor, Poetry, Pytest             |
| Graph             | NetworkX / Graphviz / D3.js        |
| Dashboard         | FastAPI + React (optionnel)        |
| Logging           | Loguru avec structured logging     |
| Monitoring        | Prometheus + Grafana (optionnel)   |
| Docker            | Docker compose                     |
| Queue             | Celery + Redis (pour async)        |

---

### Structure envisag√©e am√©lior√©e:
```
project-root/
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ models.yaml
‚îÇ   ‚îú‚îÄ‚îÄ recursion_criteria.yaml
‚îÇ   ‚îî‚îÄ‚îÄ cache_policy.yaml
‚îú‚îÄ‚îÄ orchestrator/
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ model_router.py
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py
‚îÇ   ‚îú‚îÄ‚îÄ conflict_resolver.py          # Nouveau
‚îÇ   ‚îú‚îÄ‚îÄ cache_manager.py              # Nouveau
‚îÇ   ‚îî‚îÄ‚îÄ agents/
‚îÇ       ‚îú‚îÄ‚îÄ agent_master.py
‚îÇ       ‚îú‚îÄ‚îÄ agent_normalization.py    # Nouveau
‚îÇ       ‚îú‚îÄ‚îÄ agent_identification.py
‚îÇ       ‚îú‚îÄ‚îÄ agent_webdata.py
‚îÇ       ‚îú‚îÄ‚îÄ agent_inpi.py
‚îÇ       ‚îú‚îÄ‚îÄ agent_capital.py
‚îÇ       ‚îú‚îÄ‚îÄ agent_news.py
‚îÇ       ‚îú‚îÄ‚îÄ agent_validation.py       # Nouveau
‚îÇ       ‚îú‚îÄ‚îÄ agent_recursion.py
‚îÇ       ‚îî‚îÄ‚îÄ agent_synthese.py  
‚îÇ
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ tool_normalize_name.py        # Nouveau
‚îÇ   ‚îú‚îÄ‚îÄ tool_match_enterprise.py      # Nouveau
‚îÇ   ‚îú‚îÄ‚îÄ tool_ner_extraction.py        # Nouveau
‚îÇ   ‚îú‚îÄ‚îÄ tool_identify_website.py
‚îÇ   ‚îú‚îÄ‚îÄ tool_fetch_site_data.py
‚îÇ   ‚îú‚îÄ‚îÄ tool_get_inpi_documents.py
‚îÇ   ‚îú‚îÄ‚îÄ tool_parse_inpi_documents.py
‚îÇ   ‚îú‚îÄ‚îÄ tool_extract_news.py
‚îÇ   ‚îú‚îÄ‚îÄ tool_extract_links.py
‚îÇ   ‚îú‚îÄ‚îÄ tool_validate_consistency.py  # Nouveau
‚îÇ   ‚îú‚îÄ‚îÄ tool_resolve_conflicts.py     # Nouveau
‚îÇ   ‚îú‚îÄ‚îÄ tool_prioritize_entities.py   # Nouveau
‚îÇ   ‚îú‚îÄ‚îÄ tool_generate_report.py       # Nouveau
‚îÇ   ‚îî‚îÄ‚îÄ tool_store_pg.py
‚îÇ
‚îú‚îÄ‚îÄ memory/
‚îÇ   ‚îú‚îÄ‚îÄ memory_manager.py
‚îÇ   ‚îú‚îÄ‚îÄ cache_manager.py              # Nouveau
‚îÇ   ‚îî‚îÄ‚îÄ graph_temp.py
‚îÇ
‚îú‚îÄ‚îÄ validation/                       # Nouveau dossier
‚îÇ   ‚îú‚îÄ‚îÄ data_validator.py
‚îÇ   ‚îú‚îÄ‚îÄ conflict_detector.py
‚îÇ   ‚îî‚îÄ‚îÄ scoring_engine.py
‚îÇ
‚îú‚îÄ‚îÄ monitoring/                       # Nouveau dossier
‚îÇ   ‚îú‚îÄ‚îÄ metrics_collector.py
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_api.py
‚îÇ   ‚îî‚îÄ‚îÄ performance_tracker.py
‚îÇ
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îú‚îÄ‚îÄ init.sql
‚îÇ   ‚îú‚îÄ‚îÄ migrations/
‚îÇ   ‚îî‚îÄ‚îÄ seeds/                        # Donn√©es de test
‚îÇ
‚îú‚îÄ‚îÄ frontend/                         # Nouveau (optionnel)
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îî‚îÄ‚îÄ visualization/
‚îÇ
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ test_fake_flows.py
    ‚îú‚îÄ‚îÄ test_conflict_resolution.py   # Nouveau
    ‚îú‚îÄ‚îÄ test_recursion_limits.py      # Nouveau
    ‚îî‚îÄ‚îÄ test_performance.py           # Nouveau
```

## üìä M√©triques de Succ√®s

**Quantitatives :**
- Temps moyen d'exploration : < 5 minutes pour profondeur 2
- Taux de succ√®s d'identification : > 95%
- Pr√©cision des liens capitalistiques : > 90%
- Taux de conflits r√©solus automatiquement : > 80%

**Qualitatives :**
- R√©sum√©s coh√©rents et complets
- D√©tection proactive des incoh√©rences
- Exploration intelligente sans explosion combinatoire
- Fallbacks gracieux en cas d'√©chec

---



## üîß Exemple d'architecture Technique D√©taill√©e

### 1. Orchestrateur Custom - Design Patterns & Classes

#### Pattern Principal : **State Machine + Command Pattern**

```python
# orchestrator/core.py
from enum import Enum
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from abc import ABC, abstractmethod
import asyncio
from celery import Celery

class ExecutionState(Enum):
    PENDING = "pending"
    RUNNING = "running" 
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

class TaskPriority(Enum):
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class TaskContext:
    """Context partag√© entre tous les agents"""
    session_id: str
    enterprise_name: str
    current_depth: int
    max_depth: int
    collected_data: Dict[str, Any]
    graph: 'TemporaryGraph'
    cache: 'CacheManager'
    config: Dict[str, Any]
    errors: List[str]
    metrics: Dict[str, float]

class AgentTask(ABC):
    """Interface pour toutes les t√¢ches d'agents"""
    
    def __init__(self, task_id: str, priority: TaskPriority = TaskPriority.MEDIUM):
        self.task_id = task_id
        self.priority = priority
        self.state = ExecutionState.PENDING
        self.dependencies: List[str] = []
        self.result: Optional[Any] = None
        self.error: Optional[Exception] = None
        self.start_time: Optional[float] = None
        self.end_time: Optional[float] = None
    
    @abstractmethod
    async def execute(self, context: TaskContext) -> Any:
        """Ex√©cute la t√¢che de mani√®re asynchrone"""
        pass
    
    @abstractmethod
    def can_run(self, completed_tasks: List[str]) -> bool:
        """V√©rifie si la t√¢che peut √™tre ex√©cut√©e"""
        pass
    
    def get_retry_count(self) -> int:
        return getattr(self, '_retry_count', 0)
    
    def increment_retry(self):
        self._retry_count = getattr(self, '_retry_count', 0) + 1

class OrchestrationEngine:
    """Moteur principal d'orchestration"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.celery_app = Celery('agent_orchestrator')
        self.task_queue = asyncio.PriorityQueue()
        self.running_tasks: Dict[str, asyncio.Task] = {}
        self.completed_tasks: List[str] = []
        self.failed_tasks: List[str] = []
        self.max_concurrent_tasks = config.get('max_concurrent_tasks', 5)
        self.retry_policy = config.get('retry_policy', {
            'max_retries': 3,
            'delay': 1.0,
            'backoff_factor': 2.0
        })
    
    async def execute_session(self, enterprise_name: str, session_config: Dict[str, Any]) -> 'SessionResult':
        """Point d'entr√©e principal pour une session d'exploration"""
        context = await self._create_context(enterprise_name, session_config)
        
        # Cr√©ation du pipeline de t√¢ches
        tasks = await self._create_task_pipeline(context)
        
        # Ex√©cution avec gestion des d√©pendances
        result = await self._execute_with_dependencies(tasks, context)
        
        return result
    
    async def _execute_with_dependencies(self, tasks: List[AgentTask], context: TaskContext) -> 'SessionResult':
        """Ex√©cute les t√¢ches en respectant les d√©pendances"""
        pending_tasks = {task.task_id: task for task in tasks}
        
        while pending_tasks or self.running_tasks:
            # Trouve les t√¢ches pr√™tes √† √™tre ex√©cut√©es
            ready_tasks = [
                task for task in pending_tasks.values()
                if task.can_run(self.completed_tasks) and len(self.running_tasks) < self.max_concurrent_tasks
            ]
            
            # Lance les t√¢ches pr√™tes
            for task in ready_tasks:
                await self._execute_task_async(task, context)
                del pending_tasks[task.task_id]
            
            # Attend qu'au moins une t√¢che se termine
            if self.running_tasks:
                done, pending = await asyncio.wait(
                    self.running_tasks.values(),
                    return_when=asyncio.FIRST_COMPLETED
                )
                
                for task in done:
                    task_id = self._get_task_id_from_task(task)
                    await self._handle_task_completion(task_id, task, context)
            
            await asyncio.sleep(0.1)  # √âvite la busy loop
        
        return await self._build_session_result(context)
    
    async def _execute_task_async(self, agent_task: AgentTask, context: TaskContext):
        """Ex√©cute une t√¢che de mani√®re asynchrone avec retry"""
        
        async def task_wrapper():
            for attempt in range(self.retry_policy['max_retries'] + 1):
                try:
                    agent_task.state = ExecutionState.RUNNING
                    agent_task.start_time = time.time()
                    
                    result = await agent_task.execute(context)
                    
                    agent_task.result = result
                    agent_task.state = ExecutionState.COMPLETED
                    agent_task.end_time = time.time()
                    
                    return result
                
                except Exception as e:
                    agent_task.error = e
                    agent_task.increment_retry()
                    
                    if attempt < self.retry_policy['max_retries']:
                        delay = self.retry_policy['delay'] * (self.retry_policy['backoff_factor'] ** attempt)
                        await asyncio.sleep(delay)
                    else:
                        agent_task.state = ExecutionState.FAILED
                        agent_task.end_time = time.time()
                        raise
        
        task = asyncio.create_task(task_wrapper())
        self.running_tasks[agent_task.task_id] = task
        return task
```

#### Queue Management avec Celery

```python
# orchestrator/queue_manager.py
from celery import Celery
from kombu import Queue, Exchange
from typing import Dict, Any, Optional

class QueueManager:
    """Gestionnaire des queues Celery pour les t√¢ches lourdes"""
    
    def __init__(self, redis_url: str = "redis://localhost:6379/0"):
        self.celery_app = Celery('agent_tasks')
        self.celery_app.conf.update(
            broker_url=redis_url,
            result_backend=redis_url,
            task_serializer='json',
            accept_content=['json'],
            result_serializer='json',
            timezone='UTC',
            enable_utc=True,
            task_routes={
                'agent_tasks.heavy_processing': {'queue': 'heavy'},
                'agent_tasks.llm_calls': {'queue': 'llm'},
                'agent_tasks.web_scraping': {'queue': 'web'},
                'agent_tasks.data_processing': {'queue': 'data'}
            }
        )
        
        # D√©finition des queues avec priorit√©s
        self.celery_app.conf.task_queues = (
            Queue('heavy', Exchange('heavy'), routing_key='heavy',
                  queue_arguments={'x-max-priority': 10}),
            Queue('llm', Exchange('llm'), routing_key='llm',
                  queue_arguments={'x-max-priority': 8}),
            Queue('web', Exchange('web'), routing_key='web',
                  queue_arguments={'x-max-priority': 6}),
            Queue('data', Exchange('data'), routing_key='data',
                  queue_arguments={'x-max-priority': 4}),
        )
    
    @celery_app.task(bind=True, name='agent_tasks.llm_processing')
    def process_with_llm(self, agent_name: str, input_data: Dict[str, Any], model_config: Dict[str, Any]) -> Dict[str, Any]:
        """T√¢che Celery pour les appels LLM"""
        from agents.base import create_agent
        
        agent = create_agent(agent_name, model_config)
        result = agent.process_sync(input_data)
        
        return {
            'agent': agent_name,
            'result': result,
            'execution_time': time.time() - self.request.started,
            'model_used': model_config.get('model', 'unknown')
        }
    
    @celery_app.task(bind=True, name='agent_tasks.heavy_processing')
    def process_heavy_task(self, tool_name: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """T√¢che Celery pour les traitements lourds"""
        from tools.factory import create_tool
        
        tool = create_tool(tool_name)
        result = tool.run(input_data)
        
        return {
            'tool': tool_name,
            'result': result,
            'execution_time': time.time() - self.request.started
        }
```

### 2. Gestion Synchrone vs Asynchrone

#### Strat√©gie Hybride

```python
# orchestrator/execution_strategy.py
import asyncio
from typing import List, Dict, Any, Union, Callable
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor

class ExecutionStrategy:
    """D√©termine la strat√©gie d'ex√©cution optimale"""
    
    ASYNC_TASKS = {
        'web_scraping', 'api_calls', 'database_queries', 'file_io'
    }
    
    SYNC_HEAVY_TASKS = {
        'pdf_parsing', 'nlp_processing', 'image_processing'
    }
    
    PARALLEL_TASKS = {
        'data_validation', 'entity_extraction', 'conflict_resolution'
    }
    
    def __init__(self, max_workers: int = 4):
        self.thread_pool = ThreadPoolExecutor(max_workers=max_workers)
        self.process_pool = ProcessPoolExecutor(max_workers=max_workers)
    
    async def execute_optimal(self, task_type: str, func: Callable, *args, **kwargs) -> Any:
        """Ex√©cute la fonction avec la strat√©gie optimale"""
        
        if task_type in self.ASYNC_TASKS:
            # Ex√©cution asynchrone native
            return await func(*args, **kwargs)
            
        elif task_type in self.SYNC_HEAVY_TASKS:
            # Ex√©cution dans un processus s√©par√©
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                self.process_pool, func, *args
            )
            
        elif task_type in self.PARALLEL_TASKS:
            # Ex√©cution dans un thread s√©par√©
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                self.thread_pool, func, *args
            )
            
        else:
            # Ex√©cution synchrone par d√©faut
            return func(*args, **kwargs)

# Exemple d'utilisation dans un agent
class AgentINPI(BaseAgent):
    
    async def execute(self, context: TaskContext) -> Dict[str, Any]:
        strategy = ExecutionStrategy()
        
        # R√©cup√©ration des documents (I/O intensif -> async)
        documents = await strategy.execute_optimal(
            'api_calls',
            self._fetch_inpi_documents,
            context.enterprise_name
        )
        
        # Parsing des PDFs (CPU intensif -> process)
        parsed_data = await strategy.execute_optimal(
            'pdf_parsing',
            self._parse_documents_heavy,
            documents
        )
        
        # Extraction d'entit√©s (parall√©lisable -> thread)
        entities = await strategy.execute_optimal(
            'entity_extraction',
            self._extract_entities,
            parsed_data
        )
        
        return {
            'documents': documents,
            'parsed_data': parsed_data,
            'entities': entities
        }
```

### 3. Classes et Interfaces D√©taill√©es

#### Base Classes pour Agents

```python
# agents/base.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import logging
from enum import Enum

class AgentState(Enum):
    IDLE = "idle"
    PROCESSING = "processing"
    COMPLETED = "completed"
    ERROR = "error"

@dataclass
class AgentResult:
    """R√©sultat standardis√© d'un agent"""
    agent_name: str
    success: bool
    data: Dict[str, Any]
    confidence_score: float
    execution_time: float
    errors: List[str]
    warnings: List[str]
    metadata: Dict[str, Any]

class BaseAgent(ABC):
    """Classe de base pour tous les agents"""
    
    def __init__(self, name: str, config: Dict[str, Any]):
        self.name = name
        self.config = config
        self.state = AgentState.IDLE
        self.logger = logging.getLogger(f"agent.{name}")
        self.memory = {}
        self.tools = []
        self.llm_client = None
        
    @abstractmethod
    async def execute(self, context: TaskContext) -> AgentResult:
        """M√©thode principale d'ex√©cution"""
        pass
    
    @abstractmethod
    def validate_input(self, context: TaskContext) -> bool:
        """Valide les donn√©es d'entr√©e"""
        pass
    
    async def pre_execute(self, context: TaskContext):
        """Pr√©paration avant ex√©cution"""
        self.state = AgentState.PROCESSING
        self.logger.info(f"Starting execution for {context.enterprise_name}")
    
    async def post_execute(self, result: AgentResult, context: TaskContext):
        """Nettoyage apr√®s ex√©cution"""
        self.state = AgentState.COMPLETED if result.success else AgentState.ERROR
        
        # Mise √† jour du contexte
        context.collected_data[self.name] = result.data
        context.metrics[f"{self.name}_confidence"] = result.confidence_score
        context.metrics[f"{self.name}_execution_time"] = result.execution_time
        
        # Logging
        self.logger.info(f"Completed execution: success={result.success}, confidence={result.confidence_score}")

class DataValidationMixin:
    """Mixin pour validation des donn√©es"""
    
    def validate_data_consistency(self, data: Dict[str, Any]) -> List[str]:
        """Valide la coh√©rence des donn√©es"""
        errors = []
        
        # Validation des champs obligatoires
        required_fields = getattr(self, 'REQUIRED_FIELDS', [])
        for field in required_fields:
            if field not in data or not data[field]:
                errors.append(f"Missing required field: {field}")
        
        # Validation des types
        field_types = getattr(self, 'FIELD_TYPES', {})
        for field, expected_type in field_types.items():
            if field in data and not isinstance(data[field], expected_type):
                errors.append(f"Invalid type for {field}: expected {expected_type}, got {type(data[field])}")
        
        return errors

class CacheableMixin:
    """Mixin pour gestion du cache"""
    
    def get_cache_key(self, context: TaskContext) -> str:
        """G√©n√®re une cl√© de cache"""
        return f"{self.name}:{context.enterprise_name}:{hash(str(context.config))}"
    
    async def get_cached_result(self, context: TaskContext) -> Optional[AgentResult]:
        """R√©cup√®re un r√©sultat depuis le cache"""
        cache_key = self.get_cache_key(context)
        return await context.cache.get(cache_key)
    
    async def cache_result(self, result: AgentResult, context: TaskContext):
        """Met en cache un r√©sultat"""
        cache_key = self.get_cache_key(context)
        ttl = self.config.get('cache_ttl', 3600)
        await context.cache.set(cache_key, result, ttl)
```

#### Impl√©mentation Concr√®te d'Agents

```python
# agents/agent_normalization.py
from typing import Dict, Any, List
from .base import BaseAgent, AgentResult, DataValidationMixin
from tools.factory import create_tool

class AgentNormalization(BaseAgent, DataValidationMixin):
    """Agent de normalisation des noms d'entreprises"""
    
    REQUIRED_FIELDS = ['enterprise_name']
    FIELD_TYPES = {'enterprise_name': str}
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__('normalization', config)
        self.normalize_tool = create_tool('normalize_name')
        self.match_tool = create_tool('match_enterprise')
        self.ner_tool = create_tool('ner_extraction')
    
    async def execute(self, context: TaskContext) -> AgentResult:
        start_time = time.time()
        errors = []
        warnings = []
        
        try:
            await self.pre_execute(context)
            
            # Validation des entr√©es
            if not self.validate_input(context):
                raise ValueError("Invalid input data")
            
            # Normalisation du nom
            normalized_result = await self.normalize_tool.run_async({
                'raw_name': context.enterprise_name
            })
            
            # Matching avec base de donn√©es
            match_result = await self.match_tool.run_async({
                'name_variants': normalized_result['variants']
            })
            
            # Extraction d'entit√©s nomm√©es
            ner_result = await self.ner_tool.run_async({
                'text': context.enterprise_name
            })
            
            # Consolidation des r√©sultats
            consolidated_data = {
                'original_name': context.enterprise_name,
                'normalized_name': normalized_result['normalized'],
                'variants': normalized_result['variants'],
                'matched_entities': match_result['matches'],
                'siren': match_result.get('best_match', {}).get('siren'),
                'confidence_score': match_result.get('confidence', 0.0),
                'named_entities': ner_result['entities']
            }
            
            # Validation des donn√©es
            validation_errors = self.validate_data_consistency(consolidated_data)
            if validation_errors:
                errors.extend(validation_errors)
            
            execution_time = time.time() - start_time
            
            result = AgentResult(
                agent_name=self.name,
                success=len(errors) == 0,
                data=consolidated_data,
                confidence_score=consolidated_data['confidence_score'],
                execution_time=execution_time,
                errors=errors,
                warnings=warnings,
                metadata={
                    'variants_found': len(normalized_result['variants']),
                    'matches_found': len(match_result['matches']),
                    'entities_extracted': len(ner_result['entities'])
                }
            )
            
            await self.post_execute(result, context)
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            errors.append(str(e))
            
            return AgentResult(
                agent_name=self.name,
                success=False,
                data={},
                confidence_score=0.0,
                execution_time=execution_time,
                errors=errors,
                warnings=warnings,
                metadata={}
            )
    
    def validate_input(self, context: TaskContext) -> bool:
        if not context.enterprise_name or not context.enterprise_name.strip():
            return False
        return True
```

### 4. Gestion des √âtats et Transitions

```python
# orchestrator/state_manager.py
from enum import Enum
from typing import Dict, Any, List, Optional, Callable
from dataclasses import dataclass
import asyncio

class SessionState(Enum):
    INITIALIZING = "initializing"
    NORMALIZING = "normalizing"
    IDENTIFYING = "identifying"
    COLLECTING = "collecting"
    VALIDATING = "validating"
    RECURSING = "recursing"
    SYNTHESIZING = "synthesizing"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class StateTransition:
    from_state: SessionState
    to_state: SessionState
    condition: Callable[[TaskContext], bool]
    action: Optional[Callable[[TaskContext], Any]] = None

class StateManager:
    """Gestionnaire d'√©tats pour les sessions d'exploration"""
    
    def __init__(self):
        self.transitions: List[StateTransition] = []
        self._setup_transitions()
    
    def _setup_transitions(self):
        """D√©finit les transitions d'√©tats autoris√©es"""
        self.transitions = [
            StateTransition(
                SessionState.INITIALIZING,
                SessionState.NORMALIZING,
                lambda ctx: ctx.enterprise_name is not None
            ),
            StateTransition(
                SessionState.NORMALIZING,
                SessionState.IDENTIFYING,
                lambda ctx: 'normalization' in ctx.collected_data and ctx.collected_data['normalization'].get('normalized_name')
            ),
            StateTransition(
                SessionState.IDENTIFYING,
                SessionState.COLLECTING,
                lambda ctx: 'identification' in ctx.collected_data and ctx.collected_data['identification'].get('siren')
            ),
            StateTransition(
                SessionState.COLLECTING,
                SessionState.VALIDATING,
                lambda ctx: len(ctx.collected_data) >= 3  # Au moins 3 agents ont collect√© des donn√©es
            ),
            StateTransition(
                SessionState.VALIDATING,
                SessionState.RECURSING,
                lambda ctx: (
                    'validation' in ctx.collected_data and
                    ctx.current_depth < ctx.max_depth and
                    len(ctx.collected_data.get('validation', {}).get('linked_entities', [])) > 0
                )
            ),
            StateTransition(
                SessionState.VALIDATING,
                SessionState.SYNTHESIZING,
                lambda ctx: (
                    ctx.current_depth >= ctx.max_depth or
                    len(ctx.collected_data.get('validation', {}).get('linked_entities', [])) == 0
                )
            ),
            StateTransition(
                SessionState.RECURSING,
                SessionState.COLLECTING,
                lambda ctx: True  # Retour √† la collecte pour les entit√©s li√©es
            ),
            StateTransition(
                SessionState.SYNTHESIZING,
                SessionState.COMPLETED,
                lambda ctx: 'synthesis' in ctx.collected_data
            )
        ]
    
    def get_next_state(self, current_state: SessionState, context: TaskContext) -> Optional[SessionState]:
        """D√©termine l'√©tat suivant bas√© sur les conditions"""
        for transition in self.transitions:
            if transition.from_state == current_state and transition.condition(context):
                if transition.action:
                    transition.action(context)
                return transition.to_state
        return None
    
    def can_transition(self, from_state: SessionState, to_state: SessionState, context: TaskContext) -> bool:
        """V√©rifie si une transition est autoris√©e"""
        for transition in self.transitions:
            if transition.from_state == from_state and transition.to_state == to_state:
                return transition.condition(context)
        return False
```

### 5. Monitoring et M√©triques

```python
# monitoring/metrics_collector.py
from typing import Dict, Any, List
from dataclasses import dataclass, field
import time
import psutil
import asyncio
from prometheus_client import Counter, Histogram, Gauge

@dataclass
class SystemMetrics:
    cpu_usage: float
    memory_usage: float
    disk_usage: float
    network_io: Dict[str, float]
    timestamp: float = field(default_factory=time.time)

@dataclass
class AgentMetrics:
    agent_name: str
    execution_count: int
    success_rate: float
    avg_execution_time: float
    confidence_scores: List[float]
    error_count: int
    cache_hit_rate: float

class MetricsCollector:
    """Collecteur de m√©triques pour monitoring"""
    
    def __init__(self):
        # M√©triques Prometheus
        self.agent_executions = Counter('agent_executions_total', 'Total agent executions', ['agent_name', 'status'])
        self.execution_duration = Histogram('agent_execution_duration_seconds', 'Agent execution duration', ['agent_name'])
        self.confidence_scores = Histogram('agent_confidence_scores', 'Agent confidence scores', ['agent_name'])
        self.system_resources = Gauge('system_resources', 'System resource usage', ['resource_type'])
        
        self.agent_metrics: Dict[str, AgentMetrics] = {}
        self.system_metrics: List[SystemMetrics] = []
        
    async def collect_agent_metrics(self, agent_name: str, result: AgentResult):
        """Collecte les m√©triques d'un agent"""
        # Prometheus metrics
        status = 'success' if result.success else 'error'
        self.agent_executions.labels(agent_name=agent_name, status=status).inc()
        self.execution_duration.labels(agent_name=agent_name).observe(result.execution_time)
        self.confidence_scores.labels(agent_name=agent_name).observe(result.confidence_score)
        
        # M√©triques internes
        if agent_name not in self.agent_metrics:
            self.agent_metrics[agent_name] = AgentMetrics(
                agent_name=agent_name,
                execution_count=0,
                success_rate=0.0,
                avg_execution_time=0.0,
                confidence_scores=[],
                error_count=0,
                cache_hit_rate=0.0
            )
        
        metrics = self.agent_metrics[agent_name]
        metrics.execution_count += 1
        metrics.confidence_scores.append(result.confidence_score)
        
        if not result.success:
            metrics.error_count += 1
        
        # Recalculer les moyennes
        metrics.success_rate = (metrics.execution_count - metrics.error_count) / metrics.execution_count
        metrics.avg_execution_time = (
            (metrics.avg_execution_time * (metrics.execution_count - 1) + result.execution_time) / 
            metrics.execution_count
        )
    
    async def collect_system_metrics(self):
        """Collecte les m√©triques syst√®me"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        network = psutil.net_io_counters()
        
        system_metrics = SystemMetrics(
            cpu_usage=cpu_percent,
            memory_usage=memory.percent,
            disk_usage=disk.percent,
            network_io={
                'bytes_sent': network.bytes_sent,
                'bytes_recv': network.bytes_recv
            }
        )
        
        self.system_metrics.append(system_metrics)
        
        # Prometheus metrics
        self.system_resources.labels(resource_type='cpu').set(cpu_percent)
        self.system_resources.labels(resource_type='memory').set(memory.percent)
        self.system_resources.labels(resource_type='disk').set(disk.percent)
        
        # Garder seulement les 1000 derni√®res mesures
        if len(self.system_metrics) > 1000:
            self.system_metrics = self.system_metrics[-1000:]
    
    def get_summary_report(self) -> Dict[str, Any]:
        """G√©n√®re un rapport de synth√®se"""
        return {
            'agents': {
                name: {
                    'execution_count': metrics.execution_count,
                    'success_rate': metrics.success_rate,
                    'avg_execution_time': metrics.avg_execution_time,
                    'avg_confidence': sum(metrics.confidence_scores) / len(metrics.confidence_scores) if metrics.confidence_scores else 0.0,
                    'error_count': metrics.error_count
                }
                for name, metrics in self.agent_metrics.items()
            },
            'system': {
                'current_cpu': self.system_metrics[-1].cpu_usage if self.system_metrics else 0.0,
                'current_memory': self.system_metrics[-1].memory_usage if self.system_metrics else 0.0,
                'current_disk': self.system_metrics[-1].disk_usage if self.system_metrics else 0.0
            },
            'timestamp': time.time()
        }
```




## ü™ú √âtapes de d√©veloppement

### Phase 1 ‚Äì Base agent + outils fake + validation

* [ ] Impl√©mentation de l'orchestrateur avec gestion d'erreurs
* [ ] **AgentNormalization avec outils de matching**
* [ ] Impl√©mentation des agents avec modules d'outils factices
* [ ] **Syst√®me de validation et r√©solution de conflits**
* [ ] Structure du graph m√©moire local avec scoring
* [ ] Connecteurs PostgreSQL avec nouveau sch√©ma
* [ ] **Syst√®me de cache Redis**

### Phase 2 ‚Äì M√©moire, r√©cursivit√© intelligente, profondeur

* [ ] Ajout m√©moire locale/long terme par agent
* [ ] **Crit√®res d'arr√™t intelligents avec scoring de pertinence**
* [ ] Limiteur de profondeur + pr√©vention des doublons
* [ ] **Priorisation automatique des entit√©s**
* [ ] Ajout d'un cache LRU avec TTL configurable

### Phase 3 ‚Äì Interop√©rabilit√© LLM et monitoring

* [ ] Module `model_router.py` avec fallbacks
* [ ] **Dashboard de monitoring en temps r√©el**
* [ ] Bench simple entre 3 mod√®les sur 5 t√¢ches
* [ ] **M√©triques de qualit√© et performance**
* [ ] Tests de raisonnement + logs de d√©cision

### Phase 4 ‚Äì Tests bout en bout et optimisation

* [ ] Tests sur cas d'entreprises fictives avec conflits
* [ ] **Tests de charge et limites de r√©cursivit√©**
* [ ] Exports JSON / visualisation Graph avanc√©e
* [ ] **Optimisation des performances**
* [ ] D√©finition API REST (si besoin plus tard)

### Phase 5 ‚Äì Production ready (optionnel)

* [ ] Interface web pour configuration
* [ ] Syst√®me d'alertes et notifications
* [ ] Backup automatique et restauration
* [ ] Documentation utilisateur compl√®te

---