#!/usr/bin/env python3
"""
Script de test sp√©cialis√© pour l'orchestrateur.
"""

import asyncio
import sys
import time
from uuid import uuid4

sys.path.append('/app')

from orchestrator.core import OrchestrationEngine, TaskContext
from orchestrator.cache_manager import CacheManager
from loguru import logger


async def test_orchestrator_initialization():
    """Test l'initialisation de l'orchestrateur."""
    print("üéØ Test d'initialisation de l'orchestrateur...")
    
    config = {
        'max_concurrent_tasks': 5,
        'session_timeout_minutes': 30,
        'models': {
            'default_model': 'gpt-4o',
            'fallback_model': 'gpt-3.5-turbo'
        },
        'recursion': {
            'max_depth': 3,
            'min_participation_percent': 10.0
        }
    }
    
    orchestrator = OrchestrationEngine(config)
    
    # V√©rifications
    assert orchestrator.config == config
    assert orchestrator.max_concurrent_tasks == 5
    assert orchestrator.session_timeout_minutes == 30
    
    print("   ‚úÖ Orchestrateur initialis√© avec succ√®s")
    return orchestrator


async def test_session_creation():
    """Test la cr√©ation de sessions."""
    print("üéØ Test de cr√©ation de session...")
    
    orchestrator = OrchestrationEngine({
        'max_concurrent_tasks': 3,
        'session_timeout_minutes': 10
    })
    
    # Test de session simple
    result = await orchestrator.execute_session(
        enterprise_name="Test Enterprise",
        session_config={
            'max_depth': 1,
            'enable_recursion': False,
            'test_mode': True
        }
    )
    
    # V√©rifications
    assert 'session_id' in result
    assert 'status' in result
    assert 'execution_time' in result
    assert result['status'] in ['initialized', 'completed']
    
    print(f"   ‚úÖ Session cr√©√©e: {result['session_id']}")
    print(f"   üìä Statut: {result['status']}")
    print(f"   ‚è±Ô∏è  Temps: {result.get('execution_time', 0):.3f}s")
    
    return result


async def test_context_creation():
    """Test la cr√©ation de contextes."""
    print("üéØ Test de cr√©ation de contexte...")
    
    cache_manager = CacheManager(redis_url='redis://redis:6379/1')
    await cache_manager.connect()
    
    context = TaskContext(
        session_id=str(uuid4()),
        enterprise_name="Test Company",
        current_depth=0,
        max_depth=2,
        collected_data={},
        graph=None,
        cache=cache_manager,
        config={'test_mode': True},
        errors=[],
        metrics={}
    )
    
    # V√©rifications
    assert context.enterprise_name == "Test Company"
    assert context.current_depth == 0
    assert context.max_depth == 2
    assert context.cache is not None
    assert isinstance(context.collected_data, dict)
    assert isinstance(context.errors, list)
    assert isinstance(context.metrics, dict)
    
    print("   ‚úÖ Contexte cr√©√© avec succ√®s")
    print(f"   üè¢ Entreprise: {context.enterprise_name}")
    print(f"   üìä Session: {context.session_id}")
    
    await cache_manager.disconnect()
    return context


async def test_orchestrator_error_handling():
    """Test la gestion d'erreurs de l'orchestrateur."""
    print("üéØ Test de gestion d'erreurs...")
    
    orchestrator = OrchestrationEngine({'max_concurrent_tasks': 1})
    
    try:
        # Test avec nom d'entreprise vide
        result = await orchestrator.execute_session(
            enterprise_name="",
            session_config={'test_mode': True}
        )
        
        # Doit g√©rer l'erreur gracieusement
        assert 'error' in result or result.get('status') == 'error'
        print("   ‚úÖ Gestion d'erreur pour nom vide: OK")
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Exception captur√©e: {e}")
    
    try:
        # Test avec configuration invalide
        result = await orchestrator.execute_session(
            enterprise_name="Test",
            session_config={'max_depth': -1}  # Invalide
        )
        
        print("   ‚úÖ Gestion d'erreur pour config invalide: OK")
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Exception captur√©e: {e}")


async def test_orchestrator_metrics():
    """Test les m√©triques de l'orchestrateur."""
    print("üéØ Test des m√©triques...")
    
    orchestrator = OrchestrationEngine({
        'max_concurrent_tasks': 2,
        'session_timeout': 5
    })
    
    start_time = time.time()
    
    # Ex√©cution de plusieurs sessions
    sessions = []
    for i in range(3):
        result = await orchestrator.execute_session(
            enterprise_name=f"Company {i+1}",
            session_config={
                'max_depth': 1,
                'test_mode': True
            }
        )
        sessions.append(result)
    
    execution_time = time.time() - start_time
    
    # V√©rifications
    assert len(sessions) == 3
    successful_sessions = [s for s in sessions if s.get('status') != 'error']
    
    print(f"   ‚úÖ Sessions ex√©cut√©es: {len(sessions)}")
    print(f"   ‚úÖ Sessions r√©ussies: {len(successful_sessions)}")
    print(f"   ‚è±Ô∏è  Temps total: {execution_time:.3f}s")
    print(f"   üìä Temps moyen par session: {execution_time/len(sessions):.3f}s")
    
    return {
        'total_sessions': len(sessions),
        'successful_sessions': len(successful_sessions),
        'total_time': execution_time,
        'avg_time_per_session': execution_time / len(sessions)
    }


async def main():
    """Fonction principale des tests orchestrateur."""
    print("=" * 60)
    print("üéØ TESTS DE L'ORCHESTRATEUR")
    print("=" * 60)
    
    start_time = time.time()
    results = {}
    
    try:
        # Test 1: Initialisation
        orchestrator = await test_orchestrator_initialization()
        results['initialization'] = True
        
        # Test 2: Cr√©ation de session
        session_result = await test_session_creation()
        results['session_creation'] = session_result
        
        # Test 3: Cr√©ation de contexte
        context = await test_context_creation()
        results['context_creation'] = True
        
        # Test 4: Gestion d'erreurs
        await test_orchestrator_error_handling()
        results['error_handling'] = True
        
        # Test 5: M√©triques
        metrics = await test_orchestrator_metrics()
        results['metrics'] = metrics
        
        execution_time = time.time() - start_time
        
        print("\n" + "=" * 60)
        print("üìä R√âSUM√â DES TESTS ORCHESTRATEUR")
        print("=" * 60)
        print(f"‚è±Ô∏è  Temps d'ex√©cution total: {execution_time:.3f}s")
        print(f"‚úÖ Tests r√©ussis: {len([r for r in results.values() if r])}")
        print(f"üéØ Orchestrateur: Pleinement fonctionnel")
        
        return results
        
    except Exception as e:
        print(f"\n‚ùå Erreur lors des tests: {e}")
        import traceback
        traceback.print_exc()
        return {'error': str(e)}


if __name__ == "__main__":
    results = asyncio.run(main())
    sys.exit(0 if 'error' not in results else 1) 